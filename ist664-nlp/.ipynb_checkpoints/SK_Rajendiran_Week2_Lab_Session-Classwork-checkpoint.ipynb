{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Sathish Kumar Rajendiran\n",
    "Chapter :  Corpus Statistics and Language Modeling\n",
    "Date: 10/11/2020\n",
    "Week: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sathishrajendiran/ist664-nlp'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "# standard library\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# csv, xls, pandas & json\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import xlrd\n",
    "\n",
    "# Language Processing\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191785\n",
      "['[', 'emma', 'by', 'jane', 'austen', '1816', ']', 'volume', 'i', 'chapter', 'i', 'emma', 'woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.', 'she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', 'indulgent', 'father', ';', 'and', 'had', ',', 'in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', ',', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', '.', 'her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an']\n"
     ]
    }
   ],
   "source": [
    "# get the text of the book Emma from the Gutenberg corpus, tokenize it,\n",
    "#   and reduce the tokens to lowercase.\n",
    "file0 = nltk.corpus.gutenberg.fileids( ) [0]\n",
    "emmatext = nltk.corpus.gutenberg.raw(file0)\n",
    "emmatokens = nltk.word_tokenize(emmatext) \n",
    "emmawords = [w.lower( ) for w in emmatokens] \n",
    "# show some of the words\n",
    "print(len(emmawords))\n",
    "print(emmawords[ :110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a frequency distribution of words\n",
    "ndist = FreqDist(emmawords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", \t 12016\n",
      ". \t 6355\n",
      "the \t 5201\n",
      "to \t 5181\n",
      "and \t 4877\n",
      "of \t 4284\n",
      "i \t 3177\n",
      "a \t 3124\n",
      "-- \t 3100\n",
      "it \t 2503\n",
      "'' \t 2452\n",
      "her \t 2448\n",
      "was \t 2396\n",
      "; \t 2353\n",
      "she \t 2336\n",
      "not \t 2281\n",
      "in \t 2173\n",
      "be \t 1970\n",
      "you \t 1967\n",
      "he \t 1806\n",
      "that \t 1805\n",
      "`` \t 1735\n",
      "had \t 1623\n",
      "but \t 1441\n",
      "as \t 1436\n",
      "for \t 1346\n",
      "have \t 1320\n",
      "is \t 1241\n",
      "with \t 1215\n",
      "very \t 1202\n"
     ]
    }
   ],
   "source": [
    "# print the top 30 tokens by frequency\n",
    "nitems = ndist.most_common(30)\n",
    "for item in nitems:\n",
    "    print (item[0], '\\t', item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'emma', 'by', 'jane', 'austen', '1816', ']', 'volume', 'i', 'chapter', 'i', 'emma', 'woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.', 'she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', 'indulgent', 'father', ';', 'and', 'had', ',', 'in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', ',', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', '.', 'her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', ';', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess', ',', 'who', 'had', 'fallen', 'little', 'short', 'of', 'a', 'mother', 'in', 'affection', '.', 'sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr.', 'woodhouse', \"'s\", 'family', ',', 'less', 'as', 'a', 'governess', 'than', 'a', 'friend', ',']\n",
      "['[', 'emma', 'by', 'jane', 'austen', '1816', ']', 'volume', 'i', 'chapter', 'i', 'emma', 'woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty', '-', 'one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.', 'she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', 'indulgent', 'father', ';', 'and', 'had', ',', 'in', 'consequence', 'of', 'her', 'sister', \"'\", 's', 'marriage', ',', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', '.', 'her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses', ';', 'and', 'her', 'place', 'had', 'been', 'supplied', 'by', 'an', 'excellent', 'woman', 'as', 'governess', ',', 'who', 'had', 'fallen', 'little', 'short', 'of', 'a', 'mother', 'in', 'affection', '.', 'sixteen', 'years', 'had', 'miss', 'taylor', 'been', 'in', 'mr', '.', 'woodhouse', \"'\", 's', 'family', ',', 'less', 'as', 'a']\n"
     ]
    }
   ],
   "source": [
    "# look at other tokenization from the corpus\n",
    "emmawords2 = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "emmawords2lowercase = [w.lower() for w in emmawords2]\n",
    "\n",
    "print(emmawords[:160])\n",
    "print(emmawords2lowercase[:160])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## More on Python dictionaries and functions  ##\n",
    "\n",
    "# create two dictionaries\n",
    "emptydict = dict()\n",
    "phonedict = {'Bailey':'32-16','Char':'15-18', 'Dave': '20-15'} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'32-16'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve a value by indexing with its key.\n",
    "phonedict['Bailey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bailey': '32-16', 'Char': '15-18', 'Dave': '20-15', 'Avi': '41-54'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add a key, value pair by assigning a value to a new index.\n",
    "phonedict['Avi'] = '41-54'\n",
    "phonedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Bailey', 'Char', 'Dave', 'Avi'])\n",
      "dict_values(['32-16', '15-18', '20-15', '41-54'])\n",
      "dict_items([('Bailey', '32-16'), ('Char', '15-18'), ('Dave', '20-15'), ('Avi', '41-54')])\n"
     ]
    }
   ],
   "source": [
    "# key, values and items functions\n",
    "print(phonedict.keys())\n",
    "print(phonedict.values())\n",
    "print(phonedict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# test if a key is in the dictionary or not\n",
    "print('Char' in phonedict)\n",
    "print('Dave' not in phonedict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Bailey', '32-16')\n",
      "('Char', '15-18')\n",
      "('Dave', '20-15')\n",
      "('Avi', '41-54')\n"
     ]
    }
   ],
   "source": [
    "# loop over the key, value pairs\n",
    "for pair in phonedict.items():\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "10.8\n"
     ]
    }
   ],
   "source": [
    "# the function doublesum takes 2 numbers as parameters, either int or float\n",
    "#  and returns a result which is the sum of those numbers multiplied by 2\n",
    "def doublesum (x, y):\n",
    "    result = 2 * (x + y)\n",
    "    return result\n",
    "\n",
    "print(doublesum(3, 5))\n",
    "num = doublesum(3.4, 2)\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes a string and a list of words as parameters.\n",
    "#   It will return all the words in the list that contain the string as a substring\n",
    "def searchstring (substring, wordlist):\n",
    "    # initialize the result\n",
    "    result = [ ]\n",
    "    #  loop over all the words\n",
    "    for word in wordlist:\n",
    "        # test each word if it contains the substring\n",
    "        if substring in word:\n",
    "            # add it to the result\n",
    "            result.append(word)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['drizzle',\n",
       " 'puzzled',\n",
       " 'puzzles',\n",
       " 'puzzling',\n",
       " 'puzzled',\n",
       " 'puzzle',\n",
       " 'puzzle',\n",
       " 'puzzled']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchstring('zz', emmawords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zack\n",
      "22-15\n",
      "Room 159\n"
     ]
    }
   ],
   "source": [
    "# multiple variable assignment and use\n",
    "name, phone, location = ('Zack', '22-15', 'Room 159')\n",
    "print(name)\n",
    "print(phone)\n",
    "print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Regular Expression to match non-alphabetic characters\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched non-alphabetical\n"
     ]
    }
   ],
   "source": [
    "# this regular expression pattern matches any word that contains all non-alphabetical\n",
    "#   lower-case characters [^a-z]+\n",
    "# the beginning ^ and ending $ require the match to begin and end on a word boundary \n",
    "pattern = re.compile('^[^a-z]+$')\n",
    "\n",
    "nonAlphaMatch = pattern.match('**')\n",
    "#  if it matched, print a message\n",
    "if nonAlphaMatch: print ('matched non-alphabetical')\n",
    "\n",
    "# function that takes a word and returns true if it consists only\n",
    "#   of non-alphabetic characters  (assumes import re)\n",
    "def alpha_filter(w):\n",
    "  # pattern to match word of non-alphabetical characters\n",
    "  pattern = re.compile('^[^a-z]+$')\n",
    "  if (pattern.match(w)):\n",
    "    return True\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['emma', 'by', 'jane', 'austen', 'volume', 'i', 'chapter', 'i', 'emma', 'woodhouse', 'handsome', 'clever', 'and', 'rich', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', 'she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', 'indulgent', 'father', 'and', 'had', 'in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', 'her', 'mother', 'had', 'died', 'too', 'long', 'ago', 'for', 'her', 'to', 'have', 'more', 'than', 'an', 'indistinct', 'remembrance', 'of', 'her', 'caresses']\n",
      "161456\n"
     ]
    }
   ],
   "source": [
    "# apply the function to emmawords\n",
    "alphaemmawords = [w for w in emmawords if not alpha_filter(w)]\n",
    "print(alphaemmawords[:100])\n",
    "print(len(alphaemmawords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# get a list of stopwords from nltk\n",
    "nltkstopwords = nltk.corpus.stopwords.words('english')\n",
    "print(len(nltkstopwords))\n",
    "print(nltkstopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'emma', 'by', 'jane', 'austen', '1816', ']', 'volume', 'i', 'chapter', 'i', 'emma', 'woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',', 'with', 'a', 'comfortable', 'home', 'and', 'happy', 'disposition', ',', 'seemed', 'to', 'unite', 'some', 'of', 'the', 'best', 'blessings', 'of', 'existence', ';', 'and', 'had', 'lived', 'nearly', 'twenty-one', 'years', 'in', 'the', 'world', 'with', 'very', 'little', 'to', 'distress', 'or', 'vex', 'her', '.', 'she', 'was', 'the', 'youngest', 'of', 'the', 'two', 'daughters', 'of', 'a', 'most', 'affectionate', ',', 'indulgent', 'father', ';', 'and', 'had', ',', 'in', 'consequence', 'of', 'her', 'sister', \"'s\", 'marriage', ',', 'been', 'mistress', 'of', 'his', 'house', 'from', 'a', 'very', 'early', 'period', '.', 'her', 'mother', 'had', 'died']\n",
      "['likenesses', '?', 'you', 'know', 'nothing', 'of', 'drawing', '.', 'do', \"n't\"]\n"
     ]
    }
   ],
   "source": [
    "# check tokenization in emmawords\n",
    "print(emmawords[:100])\n",
    "print(emmawords[15300:15310])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "morestopwords = ['could','would','might','must','need','sha','wo','y',\"'s\",\"'d\",\"'ll\",\"'t\",\"'m\",\"'re\",\"'ve\", \"n't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'could', 'would', 'might', 'must', 'need', 'sha', 'wo', 'y', \"'s\", \"'d\", \"'ll\", \"'t\", \"'m\", \"'re\", \"'ve\", \"n't\"]\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltkstopwords + morestopwords\n",
    "print(len(stopwords))\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70556\n"
     ]
    }
   ],
   "source": [
    "stoppedemmawords = [w for w in alphaemmawords if not w in stopwords]\n",
    "print(len(stoppedemmawords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('mr.', 1091)\n",
      "('emma', 855)\n",
      "('mrs.', 668)\n",
      "('miss', 599)\n",
      "('harriet', 496)\n",
      "('much', 484)\n",
      "('said', 483)\n",
      "('one', 447)\n",
      "('every', 435)\n",
      "('weston', 430)\n",
      "('thing', 394)\n",
      "('think', 383)\n",
      "('well', 378)\n",
      "('elton', 378)\n",
      "('knightley', 373)\n",
      "('little', 359)\n",
      "('never', 358)\n",
      "('know', 335)\n",
      "('good', 313)\n",
      "('say', 310)\n",
      "('woodhouse', 308)\n",
      "('jane', 301)\n",
      "('quite', 282)\n",
      "('time', 275)\n",
      "('great', 263)\n",
      "('nothing', 252)\n",
      "('dear', 241)\n",
      "('always', 238)\n",
      "('man', 232)\n",
      "('fairfax', 232)\n"
     ]
    }
   ],
   "source": [
    "# use this list for a better frequency distribution\n",
    "emmadist = FreqDist(stoppedemmawords)\n",
    "emmaitems = emmadist.most_common(30)\n",
    "for item in emmaitems:\n",
    "  print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'emma', 'by', 'jane', 'austen', '1816', ']', 'volume', 'i', 'chapter', 'i', 'emma', 'woodhouse', ',', 'handsome', ',', 'clever', ',', 'and', 'rich', ',']\n",
      "[('[', 'emma'), ('emma', 'by'), ('by', 'jane'), ('jane', 'austen'), ('austen', '1816'), ('1816', ']'), (']', 'volume'), ('volume', 'i'), ('i', 'chapter'), ('chapter', 'i'), ('i', 'emma'), ('emma', 'woodhouse'), ('woodhouse', ','), (',', 'handsome'), ('handsome', ','), (',', 'clever'), ('clever', ','), (',', 'and'), ('and', 'rich'), ('rich', ',')]\n"
     ]
    }
   ],
   "source": [
    "# Bigrams and Bigram frequency distribution\n",
    "emmabigrams = list(nltk.bigrams(emmawords))\n",
    "print(emmawords[:21])\n",
    "print(emmabigrams[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'tuple'>\n",
      "((',', 'and'), 0.009813071929504393)\n"
     ]
    }
   ],
   "source": [
    "# setup for bigrams and bigram measures\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder = BigramCollocationFinder.from_words(emmawords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "\n",
    "# scored is a list of bigram pairs with their score\n",
    "print(type(scored))\n",
    "first = scored[0]\n",
    "print(type(first))\n",
    "print(first)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((',', 'and'), 0.009813071929504393)\n",
      "(('.', \"''\"), 0.006032797142633679)\n",
      "((\"''\", '``'), 0.005000391062908987)\n",
      "((';', 'and'), 0.004520687227885393)\n",
      "(('to', 'be'), 0.0031545741324921135)\n",
      "((',', \"''\"), 0.0030450765179758582)\n",
      "(('.', 'i'), 0.002972078108298355)\n",
      "((',', 'i'), 0.0029668639361785333)\n",
      "(('of', 'the'), 0.0029147222149803163)\n",
      "(('in', 'the'), 0.0023203065933206455)\n",
      "(('it', 'was'), 0.0023046640769611806)\n",
      "((';', 'but'), 0.002226451495163855)\n",
      "(('.', '``'), 0.002169095601845817)\n",
      "(('.', 'she'), 0.002153453085486352)\n",
      "(('i', 'am'), 0.00205438381520974)\n",
      "((',', 'that'), 0.001877101963135803)\n",
      "(('!', '--'), 0.0017936752092186563)\n",
      "(('--', 'and'), 0.0017415334880204396)\n",
      "(('she', 'had'), 0.0017311051437807962)\n",
      "(('she', 'was'), 0.0017102484553015095)\n",
      "(('had', 'been'), 0.0016007508407852543)\n",
      "((',', 'she'), 0.0015851083244257892)\n",
      "((',', 'but'), 0.0015798941523059676)\n",
      "(('.', 'he'), 0.0015798941523059676)\n",
      "(('it', 'is'), 0.0015538232917068592)\n",
      "((',', 'as'), 0.0015225382589879291)\n",
      "(('i', 'have'), 0.0014651823656698908)\n",
      "(('could', 'not'), 0.0014495398493104257)\n",
      "(('mr.', 'knightley'), 0.0014234689887113175)\n",
      "(('.', 'it'), 0.0013869697838725656)\n"
     ]
    }
   ],
   "source": [
    "# scores are sorted in decreasing frequency\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('to', 'be'), 0.0031545741324921135)\n",
      "(('of', 'the'), 0.0029147222149803163)\n",
      "(('in', 'the'), 0.0023203065933206455)\n",
      "(('it', 'was'), 0.0023046640769611806)\n",
      "(('i', 'am'), 0.00205438381520974)\n",
      "(('she', 'had'), 0.0017311051437807962)\n",
      "(('she', 'was'), 0.0017102484553015095)\n",
      "(('had', 'been'), 0.0016007508407852543)\n",
      "(('it', 'is'), 0.0015538232917068592)\n",
      "(('i', 'have'), 0.0014651823656698908)\n",
      "(('could', 'not'), 0.0014495398493104257)\n",
      "(('mr.', 'knightley'), 0.0014234689887113175)\n",
      "(('of', 'her'), 0.0013556847511536356)\n",
      "(('mrs.', 'weston'), 0.0012826863414761322)\n",
      "(('have', 'been'), 0.0012566154808770237)\n",
      "(('he', 'had'), 0.0012514013087572022)\n",
      "(('to', 'the'), 0.001235758792397737)\n",
      "(('do', 'not'), 0.0012253304481580937)\n",
      "(('and', 'the'), 0.0011679745548400552)\n",
      "(('he', 'was'), 0.0011575462106004119)\n",
      "(('would', 'be'), 0.0011210470057616603)\n",
      "(('mr.', 'elton'), 0.0011001903172823736)\n",
      "(('such', 'a'), 0.001042834423964335)\n",
      "(('a', 'very'), 0.0010324060797246917)\n",
      "(('of', 'his'), 0.0009906927027661184)\n",
      "(('that', 'she'), 0.0009594076700471882)\n",
      "(('to', 'have'), 0.0009594076700471882)\n",
      "(('to', 'her'), 0.0009594076700471882)\n",
      "(('did', 'not'), 0.0009541934979273665)\n",
      "(('and', 'i'), 0.0009489793258075449)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "finder.apply_word_filter(alpha_filter)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('mr.', 'knightley'), 0.0014234689887113175)\n",
      "(('mrs.', 'weston'), 0.0012826863414761322)\n",
      "(('mr.', 'elton'), 0.0011001903172823736)\n",
      "(('miss', 'woodhouse'), 0.0008864092603696848)\n",
      "(('mr.', 'weston'), 0.0008238391949318247)\n",
      "(('frank', 'churchill'), 0.0007508407852543212)\n",
      "(('mrs.', 'elton'), 0.0007299840967750345)\n",
      "(('mr.', 'woodhouse'), 0.0006830565476966395)\n",
      "(('every', 'thing'), 0.0006465573428578878)\n",
      "(('miss', 'fairfax'), 0.0006361289986182444)\n",
      "(('miss', 'bates'), 0.0005787731053002059)\n",
      "(('every', 'body'), 0.0005683447610605626)\n",
      "(('jane', 'fairfax'), 0.0005474880725812759)\n",
      "(('young', 'man'), 0.00043277628594519906)\n",
      "(('great', 'deal'), 0.00033370701566858723)\n",
      "(('said', 'emma'), 0.0003076361550694788)\n",
      "(('miss', 'smith'), 0.00029720781082983547)\n",
      "(('john', 'knightley'), 0.00028677946659019213)\n",
      "(('mrs.', 'goddard'), 0.0002711369502307271)\n",
      "(('dare', 'say'), 0.00026592277811090544)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter to remove stop words\n",
    "finder.apply_word_filter(lambda w: w in stopwords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((',', 'and'), 0.009813071929504393)\n",
      "(('.', \"''\"), 0.006032797142633679)\n",
      "((\"''\", '``'), 0.005000391062908987)\n",
      "((';', 'and'), 0.004520687227885393)\n",
      "(('to', 'be'), 0.0031545741324921135)\n",
      "((',', \"''\"), 0.0030450765179758582)\n",
      "(('.', 'i'), 0.002972078108298355)\n",
      "((',', 'i'), 0.0029668639361785333)\n",
      "(('of', 'the'), 0.0029147222149803163)\n",
      "(('in', 'the'), 0.0023203065933206455)\n",
      "(('it', 'was'), 0.0023046640769611806)\n",
      "((';', 'but'), 0.002226451495163855)\n",
      "(('.', '``'), 0.002169095601845817)\n",
      "(('.', 'she'), 0.002153453085486352)\n",
      "(('i', 'am'), 0.00205438381520974)\n",
      "((',', 'that'), 0.001877101963135803)\n",
      "(('!', '--'), 0.0017936752092186563)\n",
      "(('--', 'and'), 0.0017415334880204396)\n",
      "(('she', 'had'), 0.0017311051437807962)\n",
      "(('she', 'was'), 0.0017102484553015095)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter (on a new finder) to remove low frequency words\n",
    "finder2 = BigramCollocationFinder.from_words(emmawords)\n",
    "finder2.apply_freq_filter(2)\n",
    "scored = finder2.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((\"''\", '``'), 0.005000391062908987)\n",
      "(('to', 'be'), 0.0031545741324921135)\n",
      "(('of', 'the'), 0.0029147222149803163)\n",
      "(('in', 'the'), 0.0023203065933206455)\n",
      "(('it', 'was'), 0.0023046640769611806)\n",
      "(('--', 'and'), 0.0017415334880204396)\n",
      "(('she', 'had'), 0.0017311051437807962)\n",
      "(('she', 'was'), 0.0017102484553015095)\n",
      "(('had', 'been'), 0.0016007508407852543)\n",
      "(('it', 'is'), 0.0015538232917068592)\n",
      "(('could', 'not'), 0.0014495398493104257)\n",
      "(('mr.', 'knightley'), 0.0014234689887113175)\n",
      "((\"''\", 'said'), 0.0013817556117527439)\n",
      "(('``', 'i'), 0.0013608989232734572)\n",
      "(('of', 'her'), 0.0013556847511536356)\n",
      "(('--', 'i'), 0.0013400422347941705)\n",
      "(('mrs.', 'weston'), 0.0012826863414761322)\n",
      "(('have', 'been'), 0.0012566154808770237)\n",
      "(('he', 'had'), 0.0012514013087572022)\n",
      "(('to', 'the'), 0.001235758792397737)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter on both words of the ngram\n",
    "finder2.apply_ngram_filter(lambda w1, w2: len(w1) < 2)\n",
    "scored = finder2.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('26th', 'ult.'), 17.549130362301362)\n",
      "(('_______', 'regiment'), 17.549130362301362)\n",
      "(('_a_', '_source_'), 17.549130362301362)\n",
      "(('_amor_', '_patriae_'), 17.549130362301362)\n",
      "(('_and_', '_misery_'), 17.549130362301362)\n",
      "(('_any_', '_thing_'), 17.549130362301362)\n",
      "(('_be_', '_a_'), 17.549130362301362)\n",
      "(('_caro_', '_sposo_'), 17.549130362301362)\n",
      "(('_dissolved_', '_it_.'), 17.549130362301362)\n",
      "(('_great_', '_way_'), 17.549130362301362)\n",
      "(('_most_', '_precious_'), 17.549130362301362)\n",
      "(('_precious_', '_treasures_'), 17.549130362301362)\n",
      "(('_repentance_', '_and_'), 17.549130362301362)\n",
      "(('_rev._', '_philip_'), 17.549130362301362)\n",
      "(('_robin_', '_adair_'), 17.549130362301362)\n",
      "(('_small_', 'half-glass'), 17.549130362301362)\n",
      "(('_with_', '_time_'), 17.549130362301362)\n",
      "(('adequate', 'restoratives'), 17.549130362301362)\n",
      "(('austen', '1816'), 17.549130362301362)\n",
      "(('baronne', \"d'almane\"), 17.549130362301362)\n"
     ]
    }
   ],
   "source": [
    "### pointwise mutual information\n",
    "finder3 = BigramCollocationFinder.from_words(emmawords)\n",
    "scored = finder3.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('sore', 'throat'), 14.089698743664066)\n",
      "(('brunswick', 'square'), 13.952195219914131)\n",
      "(('william', 'larkins'), 13.089698743664067)\n",
      "(('baked', 'apples'), 12.964167861580208)\n",
      "(('box', 'hill'), 12.736061789049367)\n",
      "(('sixteen', 'miles'), 12.613670614496076)\n",
      "(('maple', 'grove'), 12.594934051914487)\n",
      "(('hair', 'cut'), 12.063703535131124)\n",
      "(('south', 'end'), 11.96416786158021)\n",
      "(('colonel', 'campbell'), 11.412234161246522)\n",
      "(('robert', 'martin'), 11.093935736550536)\n",
      "(('five', 'couple'), 10.841771230220482)\n",
      "(('vast', 'deal'), 10.76253400041056)\n",
      "(('ready', 'wit'), 10.652293431356767)\n",
      "(('donwell', 'abbey'), 10.519383018907313)\n",
      "(('musical', 'society'), 10.509114683453486)\n",
      "(('infinitely', 'superior'), 10.23081352096638)\n",
      "(('married', 'women'), 10.05727726597169)\n",
      "(('five', 'minutes'), 10.032714012931878)\n",
      "(('years', 'ago'), 9.957504131299197)\n",
      "(('three', 'months'), 9.941800048551753)\n",
      "(('depend', 'upon'), 9.928125111654678)\n",
      "(('ten', 'minutes'), 9.867013597351292)\n",
      "(('hurrying', 'away'), 9.603101372785888)\n",
      "(('lovely', 'woman'), 9.400399583128175)\n",
      "(('ten', 'years'), 9.37254163057804)\n",
      "(('last', 'night'), 9.368910380131172)\n",
      "(('frank', 'churchill'), 9.284101419843202)\n",
      "(('take', 'care'), 9.18038141066101)\n",
      "(('worthy', 'people'), 9.146544604068778)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# to get good results, must first apply frequency filter\n",
    "finder.apply_freq_filter(5)\n",
    "scored = finder.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
