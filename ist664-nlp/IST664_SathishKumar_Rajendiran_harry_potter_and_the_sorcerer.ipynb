{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Sathish Kumar Rajendiran\n",
    "Homework: 1 | debate 2016 Trump vs Hillary\n",
    "Date: 10/18/2020\n",
    "Subject: 2020-0930 IST 664- Natural Language Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sathishrajendiran/ist664-nlp'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "# standard library\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# csv, xls, pdf, pandas & json\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import xlrd\n",
    "\n",
    "# Language Processing\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "\n",
    "##  Regular Expression to match non-alphabetic characters\n",
    "import re\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_filter(w):\n",
    "  # pattern to match word of non-alphabetical characters\n",
    "    pattern = re.compile('^[^a-z]+$')\n",
    "    if(pattern.match(w)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Sorcerer.txt\r\n",
      "crimeandpunishment.txt\r\n",
      "desert.txt\r\n",
      "harry_potter_and_the_sorceror_stone.txt\r\n",
      "presidential_debate_2016.txt\r\n",
      "presidential_debate_2020.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls *.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_filter(w):\n",
    "  # pattern to match word of non-alphabetical characters\n",
    "    pattern = re.compile(' \\w+(?:-\\w+)*') # words with internal hyphens or apostrophes\n",
    "    if(pattern.match(w)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def special_filter(w):\n",
    "  # pattern to match word of non-alphabetical characters\n",
    "    pattern = re.compile('[''\\\".?!,:;/]+') # words with internal hyphens or apostrophes\n",
    "    if(pattern.match(w)):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of raw text is: 442745\n",
      "Displaying 25 of 1325 matches:\n",
      " Harry Potter and the Sorcerer 's Stone CHA\n",
      "at 's what I heard yes , their son , Harry '' Mr. Dursley stopped dead . Fear f\n",
      "e called Potter who had a son called Harry . Come to think of it , he was n't e\n",
      " n't even sure his nephew was called Harry . He 'd never even seen the boy . It\n",
      "e again ? Howard , is n't it ? '' `` Harry . Nasty , common name , if you ask m\n",
      "he tried to kill the Potter 's son , Harry . But -- he could n't . He could n't\n",
      "e saying that when he could n't kill Harry Potter , Voldemort 's power somehow \n",
      ".. but how in the name of heaven did Harry survive ? '' `` We can only guess , \n",
      "l places ? '' `` I 've come to bring Harry to his aunt and uncle . They 're the\n",
      " the street , screaming for sweets . Harry Potter come and live here ! '' `` It\n",
      "t be surprised if today was known as Harry Potter day in the future -- there wi\n",
      "-- there will be books written about Harry -- every child in our world will kno\n",
      "hough she thought he might be hiding Harry underneath it . `` Hagrid 's bringin\n",
      " this over with . '' Dumbledore took Harry in his arms and turned toward the Du\n",
      "He bent his great , shaggy head over Harry and gave him what must have been a v\n",
      " an ' James dead -- an ' poor little Harry off ter live with Muggles - '' '' Ye\n",
      "d walked to the front door . He laid Harry gently on the doorstep , took a lett\n",
      " out of his cloak , tucked it inside Harry 's blankets , and then came back to \n",
      "step of number four . `` Good luck , Harry , '' he murmured . He turned on his \n",
      "xpect astonishing things to happen . Harry Potter rolled over inside his blanke\n",
      " and saying in hushed voices : `` To Harry Potter -- the boy who lived ! '' CHA\n",
      "r boy lived in the house , too . Yet Harry Potter was still there , asleep at t\n",
      " the day . `` Up ! Get up ! Now ! '' Harry woke with a start . His aunt rapped \n",
      "r again . `` Up ! '' she screeched . Harry heard her walking toward the kitchen\n",
      "' she demanded . `` Nearly , '' said Harry . `` Well , get a move on , I want y\n"
     ]
    }
   ],
   "source": [
    "# Working with file\n",
    "try: \n",
    "    debatefile = open('/Users/sathishrajendiran/ist664-nlp/harry_potter_and_the_sorceror_stone.txt', 'r')\n",
    "    rawText = debatefile.read()\n",
    "    print('length of raw text is:',len(rawText))\n",
    "    \n",
    "except:\n",
    "    print(\"Is the file in correct directory?\")\n",
    "    \n",
    "debateTokens = nltk.word_tokenize(rawText)\n",
    "debateText = nltk.Text(debateTokens)\n",
    "debateText.concordance('harry')\n",
    "#When we are done, we close the file.\n",
    "debatefile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose to treat upper and lower case the same\n",
    "#    by putting all tokens in lower case\n",
    "# convert to lower case\n",
    "debateTokens = [w.lower() for w in debateTokens]\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "table = str.maketrans('', '', string.punctuation)\n",
    "stripped = [w.translate(table) for w in debateTokens]\n",
    "filewords = [w for w in stripped if w.isalpha() and len(debateTokens)>2]\n",
    "\n",
    "filewords = [w.lower() for w in debateTokens]\n",
    "stop_words = set(stopwords.words('english')) \n",
    "filewords = [w for w in debateTokens if not w in stop_words] \n",
    "\n",
    "custom_stopwords =['ơ̹','ơ','ơͣ','ơǝ','ơǝǝ','ơǝ','ơ','ơͥ','ǝǝ','Ơ̜','Ơ̜','ve','gon','na','you'\n",
    "                   ,'they','we','\\'re','\\'s','n\\'t','\\'ve','ơǝ']\n",
    "filewords = [w for w in debateTokens if not w in custom_stopwords] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display first 100 words from file:\n",
      "['harry', 'potter', 'and', 'the', 'sorcerer', 'stone', 'chapter', 'one', 'the', 'boy', 'who', 'lived', 'mr.', 'and', 'mrs.', 'dursley', ',', 'of', 'number', 'four', ',', 'privet', 'drive', ',', 'were', 'proud', 'to', 'say', 'that', 'were', 'perfectly', 'normal', ',', 'thank', 'very', 'much', '.', 'were', 'the', 'last', 'people', \"'d\", 'expect', 'to', 'be', 'involved', 'in', 'anything', 'strange', 'or', 'mysterious', ',', 'because', 'just', 'did', 'hold', 'with', 'such', 'nonsense', '.', 'mr.', 'dursley', 'was', 'the', 'director', 'of', 'a', 'firm', 'called', 'grunnings', ',', 'which', 'made', 'drills', '.', 'he', 'was', 'a', 'big', ',', 'beefy', 'man', 'with', 'hardly', 'any', 'neck', ',', 'although', 'he', 'did', 'have', 'a', 'very', 'large', 'mustache', '.', 'mrs.', 'dursley', 'was', 'thin', 'and', 'blonde', 'and', 'had', 'nearly', 'twice', 'the', 'usual', 'amount', 'of', 'neck', ',', 'which', 'came', 'in', 'very', 'useful', 'as', 'she', 'spent', 'so', 'much', 'of', 'her', 'time', 'craning', 'over', 'garden', 'fences', ',', 'spying', 'on', 'the', 'neighbors', '.', 'the', 'dursleys', 'had', 'a', 'small', 'son', 'called', 'dudley', 'and', 'in', 'their', 'opinion', 'there', 'was', 'no', 'finer', 'boy', 'anywhere', '.', 'the', 'dursleys', 'had', 'everything', 'wanted', ',', 'but', 'also', 'had', 'a', 'secret', ',', 'and', 'their', 'greatest', 'fear', 'was', 'that', 'somebody', 'would', 'discover', 'it', '.', 'did', 'think', 'could', 'bear', 'it', 'if', 'anyone', 'found', 'out', 'about', 'the', 'potters', '.', 'mrs.', 'potter', 'was', 'mrs.', 'dursley', 'sister', ',', 'but', 'had', 'met']\n"
     ]
    }
   ],
   "source": [
    "# display the first words\n",
    "print (\"Display first 100 words from file:\")\n",
    "print (filewords[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Display first 100 Stopwords:\n",
      "['’', 's', 'a', \"a's\", 'able', 'about', 'above', 'according', 'accordingly', 'across', 'actually', 'after', 'afterwards', 'again', 'against', \"ain't\", 'all', 'allow', 'allows', 'almost', 'alone', 'along', 'already', 'also', 'although', 'always', 'am', 'among', 'amongst', 'an', 'and', 'another', 'any', 'anybody', 'anyhow', 'anyone', 'anything', 'anyway', 'anyways', 'anywhere', 'apart', 'appear', 'appreciate', 'appropriate', 'are', \"aren't\", 'around', 'as', 'aside', 'ask', 'asking', 'associated', 'at', 'available', 'away', 'awfully', 'b', 'be', 'became', 'because', 'become', 'becomes', 'becoming', 'been', 'before', 'beforehand', 'behind', 'being', 'believe', 'below', 'beside', 'besides', 'best', 'better', 'between', 'beyond', 'both', 'brief', 'but', 'by', 'c', \"c'mon\", \"c's\", 'came', 'can', \"can't\", 'can', 'not', 'cant', 'cause', 'causes', 'certain', 'certainly', 'changes', 'clearly', 'co', 'com', 'come', 'comes', 'concerning']\n"
     ]
    }
   ],
   "source": [
    "# read a stop word file\n",
    "fstop = open('Smart.English.stop', 'r')\n",
    "stoptext = fstop.read()\n",
    "fstop.close()\n",
    "\n",
    "stopwords = nltk.word_tokenize(stoptext)\n",
    "print (\"Display first 100 Stopwords:\")\n",
    "print (stopwords[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup to process bigrams\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "finder = BigramCollocationFinder.from_words(filewords)\n",
    "# choose to use both the non-alpha word filter and a stopwords filter\n",
    "finder.apply_word_filter(alpha_filter)\n",
    "finder.apply_word_filter(lambda w: w in stopwords)\n",
    "finder.apply_word_filter(words_filter)\n",
    "finder.apply_word_filter(special_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bigrams from file with top 100 frequencies\n",
      "(('uncle', 'vernon'), 0.0011400221670976936)\n",
      "(('professor', 'mcgonagall'), 0.001002797276613712)\n",
      "(('aunt', 'petunia'), 0.0005488995619359265)\n",
      "(('harry', 'potter'), 0.00031667282419380375)\n",
      "(('mr.', 'dursley'), 0.00031667282419380375)\n",
      "(('harry', 'looked'), 0.00023222673774212277)\n",
      "(('professor', 'dumbledore'), 0.00023222673774212277)\n",
      "(('common', 'room'), 0.0002111152161292025)\n",
      "(('harry', 'felt'), 0.0002111152161292025)\n",
      "(('mrs.', 'dursley'), 0.00020055945532274238)\n",
      "(('professor', 'quirrell'), 0.00019000369451628227)\n",
      "(('hermione', 'granger'), 0.00017944793370982214)\n",
      "(('harry', 'asked'), 0.000168892172903362)\n",
      "(('harry', 'thought'), 0.000168892172903362)\n",
      "(('mr.', 'ollivander'), 0.000168892172903362)\n",
      "(('privet', 'drive'), 0.000168892172903362)\n",
      "(('great', 'hall'), 0.00015833641209690187)\n",
      "(('professor', 'flitwick'), 0.00015833641209690187)\n",
      "(('invisibility', 'cloak'), 0.00014778065129044177)\n",
      "(('madam', 'pomfrey'), 0.00013722489048398164)\n",
      "(('nicolas', 'flamel'), 0.00013722489048398164)\n",
      "(('sorcerer', 'stone'), 0.00013722489048398164)\n",
      "(('harry', 'told'), 0.0001266691296775215)\n",
      "(('madam', 'hooch'), 0.0001266691296775215)\n",
      "(('mr.', 'potter'), 0.0001266691296775215)\n",
      "(('mrs.', 'norris'), 0.0001266691296775215)\n",
      "(('fifty', 'points'), 0.00010555760806460125)\n",
      "(('house', 'cup'), 0.00010555760806460125)\n",
      "(('leaky', 'cauldron'), 0.00010555760806460125)\n",
      "(('albus', 'dumbledore'), 9.500184725814114e-05)\n",
      "(('draco', 'malfoy'), 9.500184725814114e-05)\n",
      "(('hagrid', 'looked'), 9.500184725814114e-05)\n",
      "(('harry', 'heard'), 9.500184725814114e-05)\n",
      "(('harry', 'knew'), 9.500184725814114e-05)\n",
      "(('harry', 'noticed'), 9.500184725814114e-05)\n",
      "(('harry', 'turned'), 9.500184725814114e-05)\n",
      "(('past', 'fluffy'), 9.500184725814114e-05)\n",
      "(('quidditch', 'match'), 9.500184725814114e-05)\n",
      "(('weasley', 'twins'), 9.500184725814114e-05)\n",
      "(('diagon', 'alley'), 8.4446086451681e-05)\n",
      "(('entrance', 'hall'), 8.4446086451681e-05)\n",
      "(('fat', 'lady'), 8.4446086451681e-05)\n",
      "(('george', 'weasley'), 8.4446086451681e-05)\n",
      "(('harry', 'whispered'), 8.4446086451681e-05)\n",
      "(('lee', 'jordan'), 8.4446086451681e-05)\n",
      "(('mrs.', 'figg'), 8.4446086451681e-05)\n",
      "(('professor', 'snape'), 8.4446086451681e-05)\n",
      "(('ten', 'minutes'), 8.4446086451681e-05)\n",
      "(('coming', 'back'), 7.389032564522088e-05)\n",
      "(('door', 'open'), 7.389032564522088e-05)\n",
      "(('front', 'door'), 7.389032564522088e-05)\n",
      "(('gryffindor', 'common'), 7.389032564522088e-05)\n",
      "(('harry', 'stared'), 7.389032564522088e-05)\n",
      "(('living', 'room'), 7.389032564522088e-05)\n",
      "(('miss', 'granger'), 7.389032564522088e-05)\n",
      "(('smelting', 'stick'), 7.389032564522088e-05)\n",
      "((\"'m\", 'warning'), 6.333456483876075e-05)\n",
      "(('asked', 'harry'), 6.333456483876075e-05)\n",
      "(('bloody', 'baron'), 6.333456483876075e-05)\n",
      "(('chocolate', 'frogs'), 6.333456483876075e-05)\n",
      "(('dark', 'arts'), 6.333456483876075e-05)\n",
      "(('eleven', \"o'clock\"), 6.333456483876075e-05)\n",
      "(('fast', 'asleep'), 6.333456483876075e-05)\n",
      "(('fell', 'asleep'), 6.333456483876075e-05)\n",
      "(('flavor', 'beans'), 6.333456483876075e-05)\n",
      "(('green', 'light'), 6.333456483876075e-05)\n",
      "(('gryffindor', 'tower'), 6.333456483876075e-05)\n",
      "(('harry', 'leaned'), 6.333456483876075e-05)\n",
      "(('harry', 'pulled'), 6.333456483876075e-05)\n",
      "(('harry', 'sat'), 6.333456483876075e-05)\n",
      "(('harry', 'shook'), 6.333456483876075e-05)\n",
      "(('high', 'table'), 6.333456483876075e-05)\n",
      "(('king', 'cross'), 6.333456483876075e-05)\n",
      "(('madam', 'malkin'), 6.333456483876075e-05)\n",
      "(('portrait', 'hole'), 6.333456483876075e-05)\n",
      "(('ron', 'muttered'), 6.333456483876075e-05)\n",
      "(('seamus', 'finnigan'), 6.333456483876075e-05)\n",
      "(('told', 'hagrid'), 6.333456483876075e-05)\n",
      "(('told', 'yeh'), 6.333456483876075e-05)\n",
      "(('back', 'inside'), 5.277880403230063e-05)\n",
      "(('boa', 'constrictor'), 5.277880403230063e-05)\n",
      "(('car', 'crash'), 5.277880403230063e-05)\n",
      "(('devil', 'snare'), 5.277880403230063e-05)\n",
      "(('dudley', 'gang'), 5.277880403230063e-05)\n",
      "(('goal', 'posts'), 5.277880403230063e-05)\n",
      "(('good', 'luck'), 5.277880403230063e-05)\n",
      "(('gryffindor', 'house'), 5.277880403230063e-05)\n",
      "(('gryffindor', 'table'), 5.277880403230063e-05)\n",
      "(('h.', 'potter'), 5.277880403230063e-05)\n",
      "(('harry', 'broom'), 5.277880403230063e-05)\n",
      "(('harry', 'gasped'), 5.277880403230063e-05)\n",
      "(('harry', 'heart'), 5.277880403230063e-05)\n",
      "(('harry', 'jumped'), 5.277880403230063e-05)\n",
      "(('harry', 'made'), 5.277880403230063e-05)\n",
      "(('harry', 'moved'), 5.277880403230063e-05)\n",
      "(('harry', 'nodded'), 5.277880403230063e-05)\n",
      "(('harry', 'picked'), 5.277880403230063e-05)\n",
      "(('harry', 'watched'), 5.277880403230063e-05)\n",
      "(('hospital', 'wing'), 5.277880403230063e-05)\n",
      "(('leaned', 'forward'), 5.277880403230063e-05)\n"
     ]
    }
   ],
   "source": [
    "# score by frequency and display the top 50 bigrams\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "print ()\n",
    "print (\"Bigrams from file with top 100 frequencies\")\n",
    "for item in scored[:100]:\n",
    "        print (item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score by PMI and display the top 50 bigrams\n",
    "# only use frequently occurring words in mutual information\n",
    "finder.apply_freq_filter(6)\n",
    "scored = finder.score_ngrams(bigram_measures.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('diagon', 'alley'), 13.531609909759233),\n",
       " (('flavor', 'beans'), 13.361684908316917),\n",
       " (('smelting', 'stick'), 13.209681814871868),\n",
       " (('king', 'cross'), 12.946647409038075),\n",
       " (('lee', 'jordan'), 12.887753719984508),\n",
       " (('bloody', 'baron'), 12.776722407595763),\n",
       " (('leaky', 'cauldron'), 12.36168490831692),\n",
       " (('privet', 'drive'), 12.209681814871871),\n",
       " (('chocolate', 'frogs'), 12.116572410480387),\n",
       " (('seamus', 'finnigan'), 11.98728939353542),\n",
       " (('fat', 'lady'), 11.817364392093111),\n",
       " (('portrait', 'hole'), 11.724254987701627),\n",
       " (('eleven', \"o'clock\"), 11.531609909759231),\n",
       " (('nicolas', 'flamel'), 11.42469470584272),\n",
       " (('madam', 'pomfrey'), 11.361684908316919),\n",
       " (('madam', 'hooch'), 11.361684908316917),\n",
       " (('madam', 'malkin'), 11.361684908316917),\n",
       " (('mrs.', 'figg'), 11.072178291121936),\n",
       " (('miss', 'granger'), 10.994668923901019),\n",
       " (('mrs.', 'norris'), 10.956701073701998),\n",
       " (('invisibility', 'cloak'), 10.698719895594488),\n",
       " (('fifty', 'points'), 10.693666667868206),\n",
       " (('entrance', 'hall'), 10.594971970756662),\n",
       " (('fast', 'asleep'), 10.402326892814264),\n",
       " (('aunt', 'petunia'), 10.376791800707128),\n",
       " (('dark', 'arts'), 10.233929361118546),\n",
       " (('mr.', 'ollivander'), 10.039756813429557),\n",
       " (('common', 'room'), 9.838122952259907),\n",
       " (('sorcerer', 'stone'), 9.822658691762623),\n",
       " (('ten', 'minutes'), 9.717828718542195),\n",
       " (('weasley', 'twins'), 9.593010454423373),\n",
       " (('green', 'light'), 9.554329986259313),\n",
       " (('living', 'room'), 9.525183640599797),\n",
       " (('past', 'fluffy'), 9.520382654335975),\n",
       " (('mrs.', 'dursley'), 9.512750882507916),\n",
       " (('uncle', 'vernon'), 9.49777907923224),\n",
       " (('draco', 'malfoy'), 9.43709231097494),\n",
       " (('mr.', 'dursley'), 9.309217488422785),\n",
       " (('quidditch', 'match'), 9.233929361118543),\n",
       " (('fell', 'asleep'), 9.200693031644613),\n",
       " (('house', 'cup'), 9.194434041172933),\n",
       " ((\"'m\", 'warning'), 9.1858350729175),\n",
       " (('george', 'weasley'), 9.039756813429557),\n",
       " (('gryffindor', 'tower'), 8.989867937637197),\n",
       " (('professor', 'mcgonagall'), 8.95140093900871),\n",
       " (('albus', 'dumbledore'), 8.938322544387141),\n",
       " (('great', 'hall'), 8.653865659810233),\n",
       " (('professor', 'flitwick'), 8.624719314150715),\n",
       " (('gryffindor', 'common'), 8.389138121057725),\n",
       " (('high', 'table'), 8.198454559448614),\n",
       " (('hermione', 'granger'), 7.898400964184013),\n",
       " (('mr.', 'potter'), 7.1222189736215284),\n",
       " (('front', 'door'), 6.938619035282141),\n",
       " (('door', 'open'), 6.803689455196032),\n",
       " (('professor', 'quirrell'), 6.402326892814262),\n",
       " (('coming', 'back'), 6.223595993996609),\n",
       " (('professor', 'dumbledore'), 6.195407683889751),\n",
       " (('ron', 'muttered'), 6.0498104780934785),\n",
       " (('told', 'yeh'), 5.719432604244783),\n",
       " (('harry', 'leaned'), 5.159833265421305),\n",
       " (('harry', 'felt'), 4.867051516193463),\n",
       " (('professor', 'snape'), 4.613492058727459),\n",
       " (('harry', 'shook'), 4.574870764700151),\n",
       " (('harry', 'noticed'), 4.471777271736045),\n",
       " (('harry', 'potter'), 4.3942985190583315),\n",
       " (('harry', 'asked'), 4.252942669812789),\n",
       " (('told', 'hagrid'), 4.049936593311958),\n",
       " (('harry', 'whispered'), 4.030550248476342),\n",
       " (('harry', 'stared'), 3.8379051705339435),\n",
       " (('hagrid', 'looked'), 3.7731784688589602),\n",
       " (('harry', 'thought'), 3.574870764700151),\n",
       " (('harry', 'knew'), 3.3297582668636174),\n",
       " (('harry', 'sat'), 3.2529426698127875),\n",
       " (('harry', 'looked'), 3.21838544777642),\n",
       " (('harry', 'told'), 3.205636955034432),\n",
       " (('harry', 'heard'), 3.120304901234668),\n",
       " (('harry', 'pulled'), 3.072370424170966),\n",
       " (('harry', 'turned'), 3.0629717261687155),\n",
       " (('asked', 'harry'), 2.8379051705339435)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bigrams from file with top 15 mutual information scores\n",
      "(('diagon', 'alley'), 13.531609909759233)\n",
      "(('flavor', 'beans'), 13.361684908316917)\n",
      "(('smelting', 'stick'), 13.209681814871868)\n",
      "(('king', 'cross'), 12.946647409038075)\n",
      "(('lee', 'jordan'), 12.887753719984508)\n",
      "(('bloody', 'baron'), 12.776722407595763)\n",
      "(('leaky', 'cauldron'), 12.36168490831692)\n",
      "(('privet', 'drive'), 12.209681814871871)\n",
      "(('chocolate', 'frogs'), 12.116572410480387)\n",
      "(('seamus', 'finnigan'), 11.98728939353542)\n",
      "(('fat', 'lady'), 11.817364392093111)\n",
      "(('portrait', 'hole'), 11.724254987701627)\n",
      "(('eleven', \"o'clock\"), 11.531609909759231)\n",
      "(('nicolas', 'flamel'), 11.42469470584272)\n",
      "(('madam', 'pomfrey'), 11.361684908316919)\n",
      "(('madam', 'hooch'), 11.361684908316917)\n",
      "(('madam', 'malkin'), 11.361684908316917)\n",
      "(('mrs.', 'figg'), 11.072178291121936)\n",
      "(('miss', 'granger'), 10.994668923901019)\n",
      "(('mrs.', 'norris'), 10.956701073701998)\n"
     ]
    }
   ],
   "source": [
    "print (\"\\nBigrams from file with top 15 mutual information scores\")\n",
    "for item in scored[:20]:\n",
    "        print (item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
