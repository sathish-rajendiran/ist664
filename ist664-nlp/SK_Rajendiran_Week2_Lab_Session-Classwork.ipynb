{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Sathish Kumar Rajendiran\n",
    "Chapter :  Corpus Statistics and Language Modeling\n",
    "Date: 10/11/2020\n",
    "Week: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sathishrajendiran/ist664-nlp'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "# standard library\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# csv, xls, pandas & json\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import xlrd\n",
    "\n",
    "# Language Processing\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "\n",
    "##  Regular Expression to match non-alphabetic characters\n",
    "import re\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25251\n",
      "['[', 'the', 'tragedie', 'of', 'julius', 'caesar', 'by', 'william', 'shakespeare', '1599', ']', 'actus', 'primus', '.', 'scoena', 'prima', '.', 'enter', 'flauius', ',', 'murellus', ',', 'and', 'certaine', 'commoners', 'ouer', 'the', 'stage', '.', 'flauius', '.', 'hence', ':', 'home', 'you', 'idle', 'creatures', ',', 'get', 'you', 'home', ':', 'is', 'this', 'a', 'holiday', '?', 'what', ',', 'know', 'you', 'not', '(', 'being', 'mechanicall', ')', 'you', 'ought', 'not', 'walke', 'vpon', 'a', 'labouring', 'day', ',', 'without', 'the', 'signe', 'of', 'your', 'profession', '?', 'speake', ',', 'what', 'trade', 'art', 'thou', '?', 'car', '.', 'why', 'sir', ',', 'a', 'carpenter', 'mur', '.', 'where', 'is', 'thy', 'leather', 'apron', ',', 'and', 'thy', 'rule', '?', 'what', 'dost', 'thou', 'with', 'thy', 'best', 'apparrell', 'on', '?', 'you', 'sir', ',']\n"
     ]
    }
   ],
   "source": [
    "# get the text of the book shakespeare-caesar from the Gutenberg corpus, tokenize it,\n",
    "#   and reduce the tokens to lowercase.\n",
    "file14 = nltk.corpus.gutenberg.fileids( ) [14]\n",
    "caesartext = nltk.corpus.gutenberg.raw(file14)\n",
    "caesartokens = nltk.word_tokenize(caesartext) \n",
    "caesarwords = [w.lower( ) for w in caesartokens] \n",
    "# show some of the words\n",
    "print(len(caesarwords))\n",
    "print(caesarwords[ :110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a frequency distribution of words\n",
    "ndist = FreqDist(caesarwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", \t 2204\n",
      ". \t 1275\n",
      "and \t 627\n",
      "the \t 579\n",
      "i \t 530\n",
      ": \t 499\n",
      "to \t 446\n",
      "you \t 391\n",
      "of \t 354\n",
      "? \t 296\n",
      "that \t 289\n",
      "is \t 269\n",
      "not \t 263\n",
      "a \t 259\n",
      "in \t 225\n",
      "my \t 209\n",
      "it \t 198\n",
      "'d \t 193\n",
      "caesar \t 190\n",
      "me \t 187\n",
      "he \t 177\n",
      "for \t 176\n",
      "this \t 166\n",
      "him \t 166\n",
      "will \t 163\n",
      "brutus \t 161\n",
      "his \t 157\n",
      "bru \t 153\n",
      "your \t 149\n",
      "with \t 149\n"
     ]
    }
   ],
   "source": [
    "# print the top 30 tokens by frequency\n",
    "nitems = ndist.most_common(30)\n",
    "for item in nitems:\n",
    "    print (item[0], '\\t', item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "caesarwords:\n",
      "['[', 'the', 'tragedie', 'of', 'julius', 'caesar', 'by', 'william', 'shakespeare', '1599', ']', 'actus', 'primus', '.', 'scoena', 'prima', '.', 'enter', 'flauius', ',', 'murellus', ',', 'and', 'certaine', 'commoners', 'ouer', 'the', 'stage', '.', 'flauius', '.', 'hence', ':', 'home', 'you', 'idle', 'creatures', ',', 'get', 'you', 'home', ':', 'is', 'this', 'a', 'holiday', '?', 'what', ',', 'know', 'you', 'not', '(', 'being', 'mechanicall', ')', 'you', 'ought', 'not', 'walke', 'vpon', 'a', 'labouring', 'day', ',', 'without', 'the', 'signe', 'of', 'your', 'profession', '?', 'speake', ',', 'what', 'trade', 'art', 'thou', '?', 'car', '.', 'why', 'sir', ',', 'a', 'carpenter', 'mur', '.', 'where', 'is', 'thy', 'leather', 'apron', ',', 'and', 'thy', 'rule', '?', 'what', 'dost', 'thou', 'with', 'thy', 'best', 'apparrell', 'on', '?', 'you', 'sir', ',', 'what', 'trade', 'are', 'you', '?', 'cobl', '.', 'truely', 'sir', ',', 'in', 'respect', 'of', 'a', 'fine', 'workman', ',', 'i', 'am', 'but', 'as', 'you', 'would', 'say', ',', 'a', 'cobler', 'mur', '.', 'but', 'what', 'trade', 'art', 'thou', '?', 'answer', 'me', 'directly', 'cob', '.', 'a', 'trade', 'sir', ',', 'that', 'i', 'hope', 'i', 'may', 'vse']\n",
      "\n",
      "caesarwords2lowercase:\n",
      "['[', 'the', 'tragedie', 'of', 'julius', 'caesar', 'by', 'william', 'shakespeare', '1599', ']', 'actus', 'primus', '.', 'scoena', 'prima', '.', 'enter', 'flauius', ',', 'murellus', ',', 'and', 'certaine', 'commoners', 'ouer', 'the', 'stage', '.', 'flauius', '.', 'hence', ':', 'home', 'you', 'idle', 'creatures', ',', 'get', 'you', 'home', ':', 'is', 'this', 'a', 'holiday', '?', 'what', ',', 'know', 'you', 'not', '(', 'being', 'mechanicall', ')', 'you', 'ought', 'not', 'walke', 'vpon', 'a', 'labouring', 'day', ',', 'without', 'the', 'signe', 'of', 'your', 'profession', '?', 'speake', ',', 'what', 'trade', 'art', 'thou', '?', 'car', '.', 'why', 'sir', ',', 'a', 'carpenter', 'mur', '.', 'where', 'is', 'thy', 'leather', 'apron', ',', 'and', 'thy', 'rule', '?', 'what', 'dost', 'thou', 'with', 'thy', 'best', 'apparrell', 'on', '?', 'you', 'sir', ',', 'what', 'trade', 'are', 'you', '?', 'cobl', '.', 'truely', 'sir', ',', 'in', 'respect', 'of', 'a', 'fine', 'workman', ',', 'i', 'am', 'but', 'as', 'you', 'would', 'say', ',', 'a', 'cobler', 'mur', '.', 'but', 'what', 'trade', 'art', 'thou', '?', 'answer', 'me', 'directly', 'cob', '.', 'a', 'trade', 'sir', ',', 'that', 'i', 'hope', 'i', 'may', 'vse']\n"
     ]
    }
   ],
   "source": [
    "# look at other tokenization from the corpus\n",
    "caesarwords2 = nltk.corpus.gutenberg.words('shakespeare-caesar.txt')\n",
    "caesarwords2lowercase = [w.lower() for w in caesarwords2]\n",
    "\n",
    "print(\"\\ncaesarwords:\")\n",
    "print(caesarwords[:160])\n",
    "print(\"\\ncaesarwords2lowercase:\")\n",
    "print(caesarwords2lowercase[:160])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes a string and a list of words as parameters.\n",
    "#   It will return all the words in the list that contain the string as a substring\n",
    "def searchstring (substring, wordlist):\n",
    "    # initialize the result\n",
    "    result = [ ]\n",
    "    #  loop over all the words\n",
    "    for word in wordlist:\n",
    "        # test each word if it contains the substring\n",
    "        if substring in word:\n",
    "            # add it to the result\n",
    "            result.append(word)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['whizzing', 'buzzing']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchstring('zz', caesarwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched non-alphabetical\n"
     ]
    }
   ],
   "source": [
    "# this regular expression pattern matches any word that contains all non-alphabetical\n",
    "#   lower-case characters [^a-z]+\n",
    "# the beginning ^ and ending $ require the match to begin and end on a word boundary \n",
    "pattern = re.compile('^[^a-z]+$')\n",
    "\n",
    "nonAlphaMatch = pattern.match('**')\n",
    "#  if it matched, print a message\n",
    "if nonAlphaMatch: print ('matched non-alphabetical')\n",
    "\n",
    "# function that takes a word and returns true if it consists only\n",
    "#   of non-alphabetic characters  (assumes import re)\n",
    "def alpha_filter(w):\n",
    "  # pattern to match word of non-alphabetical characters\n",
    "  pattern = re.compile('^[^a-z]+$')\n",
    "  if (pattern.match(w)):\n",
    "    return True\n",
    "  else:\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "alphacaesarwords:\n",
      "['the', 'tragedie', 'of', 'julius', 'caesar', 'by', 'william', 'shakespeare', 'actus', 'primus', 'scoena', 'prima', 'enter', 'flauius', 'murellus', 'and', 'certaine', 'commoners', 'ouer', 'the', 'stage', 'flauius', 'hence', 'home', 'you', 'idle', 'creatures', 'get', 'you', 'home', 'is', 'this', 'a', 'holiday', 'what', 'know', 'you', 'not', 'being', 'mechanicall', 'you', 'ought', 'not', 'walke', 'vpon', 'a', 'labouring', 'day', 'without', 'the', 'signe', 'of', 'your', 'profession', 'speake', 'what', 'trade', 'art', 'thou', 'car', 'why', 'sir', 'a', 'carpenter', 'mur', 'where', 'is', 'thy', 'leather', 'apron', 'and', 'thy', 'rule', 'what', 'dost', 'thou', 'with', 'thy', 'best', 'apparrell', 'on', 'you', 'sir', 'what', 'trade', 'are', 'you', 'cobl', 'truely', 'sir', 'in', 'respect', 'of', 'a', 'fine', 'workman', 'i', 'am', 'but', 'as']\n",
      "\n",
      "alphacaesarwords length:\n",
      "20683\n"
     ]
    }
   ],
   "source": [
    "# apply the function to emmawords\n",
    "alphacaesarwords = [w for w in caesarwords if not alpha_filter(w)]\n",
    "print(\"\\nalphacaesarwords:\")\n",
    "print(alphacaesarwords[:100])\n",
    "print(\"\\nalphacaesarwords length:\")\n",
    "print(len(alphacaesarwords))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# get a list of stopwords from nltk\n",
    "nltkstopwords = nltk.corpus.stopwords.words('english')\n",
    "print(len(nltkstopwords))\n",
    "print(nltkstopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'the', 'tragedie', 'of', 'julius', 'caesar', 'by', 'william', 'shakespeare', '1599', ']', 'actus', 'primus', '.', 'scoena', 'prima', '.', 'enter', 'flauius', ',', 'murellus', ',', 'and', 'certaine', 'commoners', 'ouer', 'the', 'stage', '.', 'flauius', '.', 'hence', ':', 'home', 'you', 'idle', 'creatures', ',', 'get', 'you', 'home', ':', 'is', 'this', 'a', 'holiday', '?', 'what', ',', 'know', 'you', 'not', '(', 'being', 'mechanicall', ')', 'you', 'ought', 'not', 'walke', 'vpon', 'a', 'labouring', 'day', ',', 'without', 'the', 'signe', 'of', 'your', 'profession', '?', 'speake', ',', 'what', 'trade', 'art', 'thou', '?', 'car', '.', 'why', 'sir', ',', 'a', 'carpenter', 'mur', '.', 'where', 'is', 'thy', 'leather', 'apron', ',', 'and', 'thy', 'rule', '?', 'what', 'dost']\n",
      "['to', 'brutish', 'beasts', ',', 'and', 'men', 'haue', 'lost', 'their', 'reason']\n"
     ]
    }
   ],
   "source": [
    "# check tokenization in caesarwords\n",
    "print(caesarwords[:100])\n",
    "print(caesarwords[15300:15310])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "morestopwords = ['could','would','might','must','need','sha','wo','y',\"'s\",\"'d\",\"'ll\",\"'t\",\"'m\",\"'re\",\"'ve\", \"n't\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'could', 'would', 'might', 'must', 'need', 'sha', 'wo', 'y', \"'s\", \"'d\", \"'ll\", \"'t\", \"'m\", \"'re\", \"'ve\", \"n't\"]\n"
     ]
    }
   ],
   "source": [
    "stopwords = nltkstopwords + morestopwords\n",
    "print(len(stopwords))\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10841\n"
     ]
    }
   ],
   "source": [
    "stoppedcaesarwords = [w for w in alphacaesarwords if not w in stopwords]\n",
    "print(len(stoppedcaesarwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('caesar', 190)\n",
      "('brutus', 161)\n",
      "('bru', 153)\n",
      "('haue', 147)\n",
      "('shall', 125)\n",
      "('thou', 115)\n",
      "('cassi', 107)\n",
      "('cassius', 85)\n",
      "('antony', 75)\n",
      "('come', 74)\n",
      "('let', 71)\n",
      "('good', 70)\n",
      "('know', 68)\n",
      "('enter', 64)\n",
      "('men', 64)\n",
      "('heere', 59)\n",
      "('vs', 58)\n",
      "('thy', 56)\n",
      "('man', 55)\n",
      "('thee', 55)\n",
      "('vpon', 48)\n",
      "('ant', 48)\n",
      "('well', 48)\n",
      "('lord', 44)\n",
      "('day', 43)\n",
      "('yet', 42)\n",
      "('go', 41)\n",
      "('selfe', 39)\n",
      "('caes', 39)\n",
      "('noble', 39)\n"
     ]
    }
   ],
   "source": [
    "# use this list for a better frequency distribution\n",
    "caesardist = FreqDist(stoppedcaesarwords)\n",
    "caesaritems = caesardist.most_common(30)\n",
    "for item in caesaritems:\n",
    "  print(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'the', 'tragedie', 'of', 'julius', 'caesar', 'by', 'william', 'shakespeare', '1599', ']', 'actus', 'primus', '.', 'scoena', 'prima', '.', 'enter', 'flauius', ',', 'murellus']\n",
      "[('[', 'the'), ('the', 'tragedie'), ('tragedie', 'of'), ('of', 'julius'), ('julius', 'caesar'), ('caesar', 'by'), ('by', 'william'), ('william', 'shakespeare'), ('shakespeare', '1599'), ('1599', ']'), (']', 'actus'), ('actus', 'primus'), ('primus', '.'), ('.', 'scoena'), ('scoena', 'prima'), ('prima', '.'), ('.', 'enter'), ('enter', 'flauius'), ('flauius', ','), (',', 'murellus')]\n"
     ]
    }
   ],
   "source": [
    "# Bigrams and Bigram frequency distribution\n",
    "caesarbigrams = list(nltk.bigrams(caesarwords))\n",
    "print(caesarwords[:21])\n",
    "print(caesarbigrams[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'tuple'>\n",
      "((',', 'and'), 0.017345847689200427)\n"
     ]
    }
   ],
   "source": [
    "# setup for bigrams and bigram measures\n",
    "from nltk.collocations import *\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "\n",
    "# create the bigram finder and score the bigrams by frequency\n",
    "finder = BigramCollocationFinder.from_words(caesarwords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "\n",
    "# scored is a list of bigram pairs with their score\n",
    "print(type(scored))\n",
    "first = scored[0]\n",
    "print(type(first))\n",
    "print(first)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((',', 'and'), 0.017345847689200427)\n",
      "(('bru', '.'), 0.006059165973624807)\n",
      "((',', 'i'), 0.0043958655102768205)\n",
      "((',', 'that'), 0.004277058334323393)\n",
      "(('cassi', '.'), 0.004237455942338917)\n",
      "(('.', 'i'), 0.0041582511583699655)\n",
      "((',', 'to'), 0.0024553483030375035)\n",
      "(('.', 'enter'), 0.0021385291671616965)\n",
      "(('brutus', ','), 0.002059324383192745)\n",
      "(('caesar', ','), 0.002019721991208269)\n",
      "(('i', 'will'), 0.0019801195992237932)\n",
      "((',', 'as'), 0.0019405172072393172)\n",
      "(('ant', '.'), 0.0019009148152548414)\n",
      "(('i', 'am'), 0.0019009148152548414)\n",
      "(('.', 'o'), 0.0018613124232703655)\n",
      "((',', 'for'), 0.0015840956793790346)\n",
      "((',', 'the'), 0.0015840956793790346)\n",
      "(('in', 'the'), 0.0015840956793790346)\n",
      "(('my', 'lord'), 0.0015840956793790346)\n",
      "(('.', 'what'), 0.0015444932873945585)\n",
      "((':', 'and'), 0.0015444932873945585)\n",
      "(('cask', '.'), 0.0015048908954100827)\n",
      "((\"'d\", ','), 0.001465288503425607)\n",
      "(('brut', '.'), 0.001465288503425607)\n",
      "(('it', 'is'), 0.001465288503425607)\n",
      "((',', 'but'), 0.001425686111441131)\n",
      "((',', 'he'), 0.001425686111441131)\n",
      "((':', 'for'), 0.0013860837194566553)\n",
      "((':', 'i'), 0.0013860837194566553)\n",
      "(('i', 'haue'), 0.0013860837194566553)\n"
     ]
    }
   ],
   "source": [
    "# scores are sorted in decreasing frequency\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('i', 'will'), 0.0019801195992237932)\n",
      "(('i', 'am'), 0.0019009148152548414)\n",
      "(('in', 'the'), 0.0015840956793790346)\n",
      "(('my', 'lord'), 0.0015840956793790346)\n",
      "(('it', 'is'), 0.001465288503425607)\n",
      "(('i', 'haue'), 0.0013860837194566553)\n",
      "(('to', 'the'), 0.0013464813274721792)\n",
      "(('i', 'do'), 0.001188071759534276)\n",
      "(('that', 'i'), 0.001188071759534276)\n",
      "(('and', 'i'), 0.0009504574076274207)\n",
      "(('of', 'the'), 0.0009504574076274207)\n",
      "(('you', 'are'), 0.0008712526236584689)\n",
      "(('all', 'the'), 0.0008316502316739931)\n",
      "(('he', 'is'), 0.0008316502316739931)\n",
      "(('i', 'know'), 0.0008316502316739931)\n",
      "(('my', 'selfe'), 0.0007920478396895173)\n",
      "((\"'t\", 'is'), 0.0007524454477050414)\n",
      "(('is', 'a'), 0.0007524454477050414)\n",
      "(('there', 'is'), 0.0007524454477050414)\n",
      "(('to', 'day'), 0.0007524454477050414)\n",
      "(('is', 'not'), 0.0007128430557205655)\n",
      "(('shall', 'be'), 0.0007128430557205655)\n",
      "(('in', 'his'), 0.0006732406637360896)\n",
      "(('of', 'caesar'), 0.0006732406637360896)\n",
      "(('that', 'you'), 0.0006732406637360896)\n",
      "(('the', 'capitoll'), 0.0006732406637360896)\n",
      "(('you', 'know'), 0.0006732406637360896)\n",
      "(('i', 'did'), 0.0006336382717516138)\n",
      "(('if', 'you'), 0.0006336382717516138)\n",
      "(('let', 'vs'), 0.0006336382717516138)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# apply a filter to remove non-alphabetical tokens from the emma bigram finder\n",
    "finder.apply_word_filter(alpha_filter)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('let', 'vs'), 0.0006336382717516138)\n",
      "(('mark', 'antony'), 0.0005148310957981862)\n",
      "(('marke', 'antony'), 0.00047522870381371034)\n",
      "(('thou', 'art'), 0.00043562631182923446)\n",
      "(('art', 'thou'), 0.00035642152786028277)\n",
      "(('enter', 'brutus'), 0.00035642152786028277)\n",
      "(('noble', 'brutus'), 0.00035642152786028277)\n",
      "(('thou', 'hast'), 0.00035642152786028277)\n",
      "(('caesar', 'caes'), 0.0003168191358758069)\n",
      "(('good', 'morrow'), 0.0003168191358758069)\n",
      "(('good', 'night'), 0.0003168191358758069)\n",
      "(('haue', 'done'), 0.0003168191358758069)\n",
      "(('lord', 'bru'), 0.0003168191358758069)\n",
      "(('antony', 'ant'), 0.000277216743891331)\n",
      "(('enter', 'lucius'), 0.000277216743891331)\n",
      "(('come', 'downe'), 0.00023761435190685517)\n",
      "(('euery', 'man'), 0.00023761435190685517)\n",
      "(('haue', 'seene'), 0.00023761435190685517)\n",
      "(('caesar', 'shall'), 0.00019801195992237932)\n",
      "(('caius', 'cassius'), 0.00019801195992237932)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter to remove stop words\n",
    "finder.apply_word_filter(lambda w: w in stopwords)\n",
    "scored = finder.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((',', 'and'), 0.017345847689200427)\n",
      "(('bru', '.'), 0.006059165973624807)\n",
      "((',', 'i'), 0.0043958655102768205)\n",
      "((',', 'that'), 0.004277058334323393)\n",
      "(('cassi', '.'), 0.004237455942338917)\n",
      "(('.', 'i'), 0.0041582511583699655)\n",
      "((',', 'to'), 0.0024553483030375035)\n",
      "(('.', 'enter'), 0.0021385291671616965)\n",
      "(('brutus', ','), 0.002059324383192745)\n",
      "(('caesar', ','), 0.002019721991208269)\n",
      "(('i', 'will'), 0.0019801195992237932)\n",
      "((',', 'as'), 0.0019405172072393172)\n",
      "(('ant', '.'), 0.0019009148152548414)\n",
      "(('i', 'am'), 0.0019009148152548414)\n",
      "(('.', 'o'), 0.0018613124232703655)\n",
      "((',', 'for'), 0.0015840956793790346)\n",
      "((',', 'the'), 0.0015840956793790346)\n",
      "(('in', 'the'), 0.0015840956793790346)\n",
      "(('my', 'lord'), 0.0015840956793790346)\n",
      "(('.', 'what'), 0.0015444932873945585)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter (on a new finder) to remove low frequency words\n",
    "finder2 = BigramCollocationFinder.from_words(caesarwords)\n",
    "finder2.apply_freq_filter(2)\n",
    "scored = finder2.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('bru', '.'), 0.006059165973624807)\n",
      "(('cassi', '.'), 0.004237455942338917)\n",
      "(('brutus', ','), 0.002059324383192745)\n",
      "(('caesar', ','), 0.002019721991208269)\n",
      "(('ant', '.'), 0.0019009148152548414)\n",
      "(('in', 'the'), 0.0015840956793790346)\n",
      "(('my', 'lord'), 0.0015840956793790346)\n",
      "(('cask', '.'), 0.0015048908954100827)\n",
      "((\"'d\", ','), 0.001465288503425607)\n",
      "(('brut', '.'), 0.001465288503425607)\n",
      "(('it', 'is'), 0.001465288503425607)\n",
      "(('him', ','), 0.0013464813274721792)\n",
      "(('to', 'the'), 0.0013464813274721792)\n",
      "(('me', ','), 0.001188071759534276)\n",
      "(('that', 'i'), 0.001188071759534276)\n",
      "(('cassius', ','), 0.0011484693675498001)\n",
      "(('luc', '.'), 0.001108866975565324)\n",
      "(('antony', ','), 0.0009900597996118966)\n",
      "(('you', ','), 0.0009900597996118966)\n",
      "(('and', 'i'), 0.0009504574076274207)\n"
     ]
    }
   ],
   "source": [
    "# apply a filter on both words of the ngram\n",
    "finder2.apply_ngram_filter(lambda w1, w2: len(w1) < 2)\n",
    "scored = finder2.score_ngrams(bigram_measures.raw_freq)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('affections', \"sway'd\"), 14.62405290271976)\n",
      "(('attendants', 'absent'), 14.62405290271976)\n",
      "(('ayre-lesse', 'dungeon'), 14.62405290271976)\n",
      "(('beaten', 'brasse'), 14.62405290271976)\n",
      "(('benches', '4.ple'), 14.62405290271976)\n",
      "(('blacke', 'sentence'), 14.62405290271976)\n",
      "(('bussling', 'rumor'), 14.62405290271976)\n",
      "(('captiue', 'bonds'), 14.62405290271976)\n",
      "(('carries', 'anger'), 14.62405290271976)\n",
      "(('cauerne', 'darke'), 14.62405290271976)\n",
      "(('chimney', 'tops'), 14.62405290271976)\n",
      "(('comets', 'seen'), 14.62405290271976)\n",
      "(('commended', 'beauty'), 14.62405290271976)\n",
      "(('craues', 'warie'), 14.62405290271976)\n",
      "(('cynicke', 'rime'), 14.62405290271976)\n",
      "(('darts', 'inuenomed'), 14.62405290271976)\n",
      "(('deceitfull', 'iades'), 14.62405290271976)\n",
      "(('dis-ioynes', 'remorse'), 14.62405290271976)\n",
      "(('disturbed', 'skie'), 14.62405290271976)\n",
      "(('diuers', \"sland'rous\"), 14.62405290271976)\n"
     ]
    }
   ],
   "source": [
    "### pointwise mutual information\n",
    "finder3 = BigramCollocationFinder.from_words(caesarwords)\n",
    "scored = finder3.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:20]:\n",
    "    print (bscore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('caius', 'ligarius'), 10.075616278023718)\n",
      "(('metellus', 'cymber'), 10.075616278023718)\n",
      "(('mine', 'owne'), 9.027117760332526)\n",
      "(('fell', 'downe'), 8.837456540828954)\n",
      "(('mark', 'antony'), 8.288319008307367)\n",
      "(('marke', 'antony'), 7.658268618057676)\n",
      "(('good', 'morrow'), 7.587879290166276)\n",
      "(('thou', 'hast'), 7.141132931160094)\n",
      "(('honourable', 'men'), 7.138626075549519)\n",
      "((\"did'st\", 'thou'), 7.100490946662747)\n",
      "(('haue', 'seene'), 7.0093430586045535)\n",
      "(('haue', 'beene'), 6.938953730713154)\n",
      "(('caius', 'cassius'), 6.836150343328329)\n",
      "(('enter', 'lucius'), 6.73096810663627)\n",
      "(('euery', 'man'), 6.620300767858655)\n",
      "(('let', 'vs'), 6.616324788087507)\n",
      "(('thou', 'art'), 6.5941382806379565)\n",
      "(('haue', 'heard'), 6.576383651328445)\n",
      "(('come', 'downe'), 6.476000081754956)\n",
      "(('art', 'thou'), 6.304631663442972)\n",
      "(('good', 'night'), 6.2468423723312085)\n",
      "(('haue', 'done'), 5.9008186018263835)\n",
      "(('shall', 'finde'), 5.892733871694697)\n",
      "(('antony', 'ant'), 5.6176266335603255)\n",
      "(('decius', 'brutus'), 5.527601278242166)\n",
      "(('noble', 'brutus'), 5.1776588071852085)\n",
      "(('lord', 'bru'), 4.9072334413898115)\n",
      "(('caesar', 'caes'), 4.768795075526565)\n",
      "(('enter', 'antony'), 4.717162307111241)\n",
      "(('great', 'caesar'), 4.675685671135081)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# to get good results, must first apply frequency filter\n",
    "finder.apply_freq_filter(5)\n",
    "scored = finder.score_ngrams(bigram_measures.pmi)\n",
    "for bscore in scored[:30]:\n",
    "    print (bscore)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
