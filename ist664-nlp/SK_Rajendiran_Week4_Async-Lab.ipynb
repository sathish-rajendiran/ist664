{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Sathish Kumar Rajendiran\n",
    "Chapter :  POS Tagging and Introduction to Machine Learning\n",
    "Date: 10/24/2020\n",
    "Week: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/sathishrajendiran/ist664-nlp'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "\n",
    "# standard library\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# csv, xls, pandas & json\n",
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import xlrd\n",
    "\n",
    "# Language Processing\n",
    "import nltk\n",
    "from nltk import FreqDist\n",
    "\n",
    "# web requests\n",
    "from urllib import request\n",
    "\n",
    "\n",
    "##  Regular Expression to match non-alphabetic characters\n",
    "import re\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')], [('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')]] \n",
      "\n",
      "[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.'), ('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Lab Week 4 - POS tagging in NLTK\n",
    "# This file has small examples that are meant to be run individually\n",
    "#   in the Python shell\n",
    "\n",
    "import nltk\n",
    "\n",
    "# POS Tagged Corpora:  Brown and Penn Treebank\n",
    "# the Brown corpus has its own set of POS tags\n",
    "from nltk.corpus import brown\n",
    "# the tagged_sents function gives POS tagged sentences and tagged_words gives POS tagged words\n",
    "print(brown.tagged_sents()[:2], '\\n')\n",
    "print(brown.tagged_words()[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The', 'AT')\n",
      "<class 'tuple'>\n",
      "The\n",
      "AT\n"
     ]
    }
   ],
   "source": [
    "# Each tagged word is a pair, which Python calls a tuple  \n",
    "#  it behaves like a list except that you can't change the elements (immutable)\n",
    "wordtag = brown.tagged_words()[0]\n",
    "print(wordtag)\n",
    "print(type(wordtag))\n",
    "print(wordtag[0])\n",
    "print(wordtag[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction'] \n",
      "\n",
      "[('It', 'PRON'), ('was', 'VERB'), ('among', 'ADP'), ('these', 'DET'), ('that', 'ADP'), ('Hinkle', 'NOUN'), ('identified', 'VERB'), ('a', 'DET'), ('photograph', 'NOUN'), ('of', 'ADP'), ('Barco', 'NOUN'), ('!', '.'), ('!', '.'), ('For', 'ADP'), ('it', 'PRON'), ('seems', 'VERB'), ('that', 'ADP'), ('Barco', 'NOUN'), (',', '.'), ('fancying', 'VERB'), ('himself', 'PRON'), ('a', 'DET'), (\"ladies'\", 'NOUN'), ('man', 'NOUN'), ('(', '.'), ('and', 'CONJ'), ('why', 'ADV'), ('not', 'ADV'), (',', '.'), ('after', 'ADP'), ('seven', 'NUM'), ('marriages', 'NOUN'), ('?', '.'), ('?', '.'), (')', '.'), (',', '.'), ('had', 'VERB'), ('listed', 'VERB'), ('himself', 'PRON'), ('for', 'ADP'), ('Mormon', 'NOUN'), ('Beard', 'NOUN'), ('roles', 'NOUN'), ('at', 'ADP'), ('the', 'DET'), ('instigation', 'NOUN'), ('of', 'ADP'), ('his', 'DET'), ('fourth', 'ADJ'), ('murder', 'NOUN')]\n",
      "[('now', 'RB'), ('im', 'PRP'), ('left', 'VBD'), ('with', 'IN'), ('this', 'DT'), ('gay', 'JJ'), ('name', 'NN'), (':P', 'UH'), ('PART', 'VB'), ('hey', 'UH'), ('everyone', 'NN'), ('ah', 'UH'), ('well', 'UH'), ('NICK', 'NN'), (':', ':'), ('U7', 'NNP'), ('U7', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('gay', 'JJ'), ('name', 'NN'), ('.', '.'), ('.', 'SYM'), ('ACTION', 'NN'), ('gives', 'VBZ'), ('U121', 'NNP'), ('a', 'DT'), ('golf', 'NN'), ('clap', 'NN'), ('.', '.'), (':)', 'UH'), ('JOIN', 'VB'), ('hi', 'UH'), ('U59', 'NNP'), ('26', 'CD'), ('/', 'CC'), ('m', 'NN'), ('/', 'CC'), ('ky', 'NNP'), ('women', 'NNS'), ('that', 'WDT'), ('are', 'VBP'), ('nice', 'JJ'), ('please', 'VB'), ('pm', 'VB'), ('me', 'PRP'), ('JOIN', 'VB'), ('PART', 'VB'), ('there', 'RB'), ('ya', 'PRP')]\n"
     ]
    }
   ],
   "source": [
    "# the brown corpus can also be accessed by category\n",
    "print(brown.categories(), '\\n')\n",
    "\n",
    "brown_humor_tagged = brown.tagged_words(categories='humor', tagset='universal')\n",
    "print(brown_humor_tagged[:50])\n",
    "\n",
    "# the chat corpus uses Penn POS tags\n",
    "print(nltk.corpus.nps_chat.tagged_words()[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "( (S \n",
      "    (NP-SBJ \n",
      "      (NP (NNP Pierre) (NNP Vinken) )\n",
      "      (, ,) \n",
      "      (ADJP \n",
      "        (NP (CD 61) (NNS years) )\n",
      "        (JJ old) )\n",
      "      (, ,) ) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Penn treebank\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "# use corpus methods to get the text as strings and as tokens as before\n",
    "treebank_text = treebank.raw()\n",
    "print(treebank_text[:150], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pierre', 'Vinken', ',', '61', 'years', 'old', ',', 'will', 'join', 'the', 'board', 'as', 'a', 'nonexecutive', 'director', 'Nov.', '29', '.', 'Mr.', 'Vinken']\n",
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.'), ('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'NNP'), ('publishing', 'VBG'), ('group', 'NN'), ('.', '.'), ('Rudolph', 'NNP'), ('Agnew', 'NNP'), (',', ','), ('55', 'CD'), ('years', 'NNS'), ('old', 'JJ'), ('and', 'CC'), ('former', 'JJ'), ('chairman', 'NN'), ('of', 'IN'), ('Consolidated', 'NNP'), ('Gold', 'NNP'), ('Fields', 'NNP'), ('PLC', 'NNP'), (',', ','), ('was', 'VBD'), ('named', 'VBN'), ('*-1', '-NONE-'), ('a', 'DT')]\n"
     ]
    }
   ],
   "source": [
    "treebank_tokens = treebank.words()\n",
    "print(treebank_tokens[:20])\n",
    "\n",
    "# but we also have functions to get words with tags and sentences with tagged words\n",
    "treebank_tagged_words = treebank.tagged_words()\n",
    "print(treebank_tagged_words[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')], [('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'NNP'), ('publishing', 'VBG'), ('group', 'NN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "treebank_tagged = treebank.tagged_sents()\n",
    "print(treebank_tagged[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['NNP', ',', 'CD', 'NNS', 'JJ', 'MD', 'VB', 'DT', 'NN', 'IN', '.', 'VBZ', 'VBG', 'CC', 'VBD', 'VBN', '-NONE-', 'RB', 'TO', 'PRP', 'RBR', 'WDT', 'VBP', 'RP', 'PRP$', 'JJS', 'POS', '``', 'EX', \"''\", 'WP', ':', 'JJR', 'WRB', '$', 'NNPS', 'WP$', '-LRB-', '-RRB-', 'PDT', 'RBS', 'FW', 'UH', 'SYM', 'LS', '#']) \n",
      "\n",
      "NN 13166\n",
      "IN 9857\n",
      "NNP 9410\n",
      "DT 8165\n",
      "-NONE- 6592\n",
      "NNS 6047\n",
      "JJ 5834\n",
      ", 4886\n",
      ". 3874\n",
      "CD 3546\n",
      "VBD 3043\n",
      "RB 2822\n",
      "VB 2554\n",
      "CC 2265\n",
      "TO 2179\n",
      "VBN 2134\n",
      "VBZ 2125\n",
      "PRP 1716\n",
      "VBG 1460\n",
      "VBP 1321\n",
      "MD 927\n",
      "POS 824\n",
      "PRP$ 766\n",
      "$ 724\n",
      "`` 712\n",
      "'' 694\n",
      ": 563\n",
      "WDT 445\n",
      "JJR 381\n",
      "NNPS 244\n",
      "WP 241\n",
      "RP 216\n",
      "JJS 182\n",
      "WRB 178\n",
      "RBR 136\n",
      "-RRB- 126\n",
      "-LRB- 120\n",
      "EX 88\n",
      "RBS 35\n",
      "PDT 27\n",
      "# 16\n",
      "WP$ 14\n",
      "LS 13\n",
      "FW 4\n",
      "UH 3\n",
      "SYM 1\n",
      "dict_keys(['N', ',', 'C', 'J', 'M', 'V', 'D', 'I', '.', '-', 'R', 'T', 'P', 'W', '`', 'E', \"'\", ':', '$', 'F', 'U', 'S', 'L', '#']) \n",
      "\n",
      "N 28867\n",
      "V 12637\n",
      "I 9857\n",
      "D 8165\n",
      "- 6838\n",
      "J 6397\n",
      "C 5811\n",
      ", 4886\n",
      ". 3874\n",
      "P 3333\n",
      "R 3209\n",
      "T 2179\n",
      "M 927\n",
      "W 878\n",
      "$ 724\n",
      "` 712\n",
      "' 694\n",
      ": 563\n",
      "E 88\n",
      "# 16\n",
      "L 13\n",
      "F 4\n",
      "U 3\n",
      "S 1\n"
     ]
    }
   ],
   "source": [
    "## Frequency distribution of tags in Penn Treebank\n",
    "tag_fd = nltk.FreqDist(tag for (word, tag) in treebank_tagged_words)\n",
    "print(tag_fd.keys(), '\\n')\n",
    "\n",
    "for tag,freq in tag_fd.most_common():\n",
    "    print (tag, freq)\n",
    "\n",
    "# use the first letter of the POS tag to get classes of tags\n",
    "tag_classes_fd = nltk.FreqDist(tag[0] for (word, tag) in treebank_tagged_words)\n",
    "print(tag_classes_fd.keys(), '\\n')\n",
    "for tag,freq in tag_classes_fd.most_common():\n",
    "    print (tag, freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NN'), ('Vinken', 'NN'), (',', 'NN'), ('61', 'NN'), ('years', 'NN'), ('old', 'NN'), (',', 'NN'), ('will', 'NN'), ('join', 'NN'), ('the', 'NN'), ('board', 'NN'), ('as', 'NN'), ('a', 'NN'), ('nonexecutive', 'NN'), ('director', 'NN'), ('Nov.', 'NN'), ('29', 'NN'), ('.', 'NN'), ('Mr.', 'NN'), ('Vinken', 'NN'), ('is', 'NN'), ('chairman', 'NN'), ('of', 'NN'), ('Elsevier', 'NN'), ('N.V.', 'NN'), (',', 'NN'), ('the', 'NN'), ('Dutch', 'NN'), ('publishing', 'NN'), ('group', 'NN'), ('.', 'NN'), ('Rudolph', 'NN'), ('Agnew', 'NN'), (',', 'NN'), ('55', 'NN'), ('years', 'NN'), ('old', 'NN'), ('and', 'NN'), ('former', 'NN'), ('chairman', 'NN'), ('of', 'NN'), ('Consolidated', 'NN'), ('Gold', 'NN'), ('Fields', 'NN'), ('PLC', 'NN'), (',', 'NN'), ('was', 'NN'), ('named', 'NN'), ('*-1', 'NN'), ('a', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## POS Tagging\n",
    "\n",
    "# Separating the data into training and test data\n",
    "size = int(len(treebank_tagged) * 0.9)\n",
    "treebank_train = treebank_tagged[:size]\n",
    "treebank_test = treebank_tagged[size:]\n",
    "\n",
    "# Default Tagger assign 'NN' to every word\n",
    "# creates the tagger\n",
    "t0 = nltk.DefaultTagger('NN')\n",
    "# show the effect of the tagger by tagging the first 50 words\n",
    "print(t0.tag(treebank_tokens[:50]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14697201017811704\n",
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.'), ('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'JJ'), ('publishing', 'NN'), ('group', 'NN'), ('.', '.'), ('Rudolph', 'NNP'), ('Agnew', 'NNP'), (',', ','), ('55', 'CD'), ('years', 'NNS'), ('old', 'JJ'), ('and', 'CC'), ('former', 'JJ'), ('chairman', 'NN'), ('of', 'IN'), ('Consolidated', 'NNP'), ('Gold', 'NNP'), ('Fields', 'NNP'), ('PLC', 'NNP'), (',', ','), ('was', 'VBD'), ('named', 'VBN'), ('*-1', '-NONE-'), ('a', 'DT')]\n"
     ]
    }
   ],
   "source": [
    "# evaluate function applies the tagger t0 to the untagged version of treebank\n",
    "#   and compares with the tagged version\n",
    "print(t0.evaluate(treebank_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.'), ('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'JJ'), ('publishing', 'NN'), ('group', 'NN'), ('.', '.'), ('Rudolph', 'NNP'), ('Agnew', 'NNP'), (',', ','), ('55', 'CD'), ('years', 'NNS'), ('old', 'JJ'), ('and', 'CC'), ('former', 'JJ'), ('chairman', 'NN'), ('of', 'IN'), ('Consolidated', 'NNP'), ('Gold', 'NNP'), ('Fields', 'NNP'), ('PLC', 'NNP'), (',', ','), ('was', 'VBD'), ('named', 'VBN'), ('*-1', '-NONE-'), ('a', 'DT')]\n"
     ]
    }
   ],
   "source": [
    "# Unigram tagger learns tag with the highest probability for each word\n",
    "# creates the tagger on the training set\n",
    "t1 = nltk.UnigramTagger(treebank_train)\n",
    "# show the effect of the tagger by tagging the first 50 words\n",
    "print(t1.tag(treebank_tokens[:50]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8627989821882952\n",
      "0.8905852417302799\n"
     ]
    }
   ],
   "source": [
    "# evaluates the tagger on the test set\n",
    "print(t1.evaluate(treebank_test))\n",
    "\n",
    "# Bigram Tagging with Backoff to Combine Taggers\n",
    "# create a sequence of taggers with backoff to get a bigram tagger\n",
    "t0 = nltk.DefaultTagger('NN')\n",
    "t1 = nltk.UnigramTagger(treebank_train, backoff=t0)\n",
    "t2 = nltk.BigramTagger(treebank_train, backoff=t1)\n",
    "# Accuracy with BigramTagger: \n",
    "print(t2.evaluate(treebank_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Three Calgarians have found a rather unusual way of leaving snow and ice behind.', 'They set off this week on foot and by camels on a grueling trek across the burning Arabian desert.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Using the bigram tagger on some new text\n",
    "text = \"Three Calgarians have found a rather unusual way of leaving snow and ice behind. They set off this week on foot and by camels on a grueling trek across the burning Arabian desert.\"\n",
    "\n",
    "# But we should separate the text into sentences first\n",
    "textsplit = nltk.sent_tokenize(text)\n",
    "print(textsplit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Three', 'Calgarians', 'have', 'found', 'a', 'rather', 'unusual', 'way', 'of', 'leaving', 'snow', 'and', 'ice', 'behind', '.'], ['They', 'set', 'off', 'this', 'week', 'on', 'foot', 'and', 'by', 'camels', 'on', 'a', 'grueling', 'trek', 'across', 'the', 'burning', 'Arabian', 'desert', '.']]\n"
     ]
    }
   ],
   "source": [
    "# apply the word tokenizer to each sentence\n",
    "tokentext = [nltk.word_tokenize(sent) for sent in textsplit]\n",
    "print(tokentext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Three', 'CD'), ('Calgarians', 'NN'), ('have', 'VBP'), ('found', 'VBN'), ('a', 'DT'), ('rather', 'RB'), ('unusual', 'JJ'), ('way', 'NN'), ('of', 'IN'), ('leaving', 'VBG'), ('snow', 'NN'), ('and', 'CC'), ('ice', 'NN'), ('behind', 'IN'), ('.', '.')], [('They', 'PRP'), ('set', 'VBN'), ('off', 'RP'), ('this', 'DT'), ('week', 'NN'), ('on', 'IN'), ('foot', 'NN'), ('and', 'CC'), ('by', 'IN'), ('camels', 'NN'), ('on', 'IN'), ('a', 'DT'), ('grueling', 'NN'), ('trek', 'NN'), ('across', 'IN'), ('the', 'DT'), ('burning', 'NN'), ('Arabian', 'NN'), ('desert', 'NN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# use the t2 bigram tagger to tag each sentence tokens\n",
    "taggedtext = [t2.tag(tokens) for tokens in tokentext]\n",
    "print(taggedtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Three', 'CD'), ('Calgarians', 'NNPS'), ('have', 'VBP'), ('found', 'VBN'), ('a', 'DT'), ('rather', 'RB'), ('unusual', 'JJ'), ('way', 'NN'), ('of', 'IN'), ('leaving', 'VBG'), ('snow', 'NN'), ('and', 'CC'), ('ice', 'NN'), ('behind', 'NN'), ('.', '.')], [('They', 'PRP'), ('set', 'VBD'), ('off', 'RP'), ('this', 'DT'), ('week', 'NN'), ('on', 'IN'), ('foot', 'NN'), ('and', 'CC'), ('by', 'IN'), ('camels', 'NNS'), ('on', 'IN'), ('a', 'DT'), ('grueling', 'NN'), ('trek', 'NN'), ('across', 'IN'), ('the', 'DT'), ('burning', 'NN'), ('Arabian', 'JJ'), ('desert', 'NN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# use the Stanford POS tagger to tag each sentence tokens\n",
    "taggedtextStanford = [nltk.pos_tag(tokens) for tokens in tokentext]\n",
    "print(taggedtextStanford)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Three', 'CD'), ('Calgarians', 'NN'), ('have', 'VBP'), ('found', 'VBN'), ('a', 'DT'), ('rather', 'RB'), ('unusual', 'JJ'), ('way', 'NN'), ('of', 'IN'), ('leaving', 'VBG'), ('snow', 'NN'), ('and', 'CC'), ('ice', 'NN'), ('behind', 'IN'), ('.', '.'), ('They', 'PRP'), ('set', 'VBN'), ('off', 'RP'), ('this', 'DT'), ('week', 'NN'), ('on', 'IN'), ('foot', 'NN'), ('and', 'CC'), ('by', 'IN'), ('camels', 'NN'), ('on', 'IN'), ('a', 'DT'), ('grueling', 'NN'), ('trek', 'NN'), ('across', 'IN'), ('the', 'DT'), ('burning', 'NN'), ('Arabian', 'NN'), ('desert', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# show how to flatten a list of tagged tokens\n",
    "taggedtext_flat = [pair for sent in taggedtext for pair in sent]\n",
    "print(taggedtext_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Three', 'CD'), ('Calgarians', 'NNPS'), ('have', 'VBP'), ('found', 'VBN'), ('a', 'DT'), ('rather', 'RB'), ('unusual', 'JJ'), ('way', 'NN'), ('of', 'IN'), ('leaving', 'VBG'), ('snow', 'NN'), ('and', 'CC'), ('ice', 'NN'), ('behind', 'NN'), ('.', '.'), ('They', 'PRP'), ('set', 'VBD'), ('off', 'RP'), ('this', 'DT'), ('week', 'NN'), ('on', 'IN'), ('foot', 'NN'), ('and', 'CC'), ('by', 'IN'), ('camels', 'NNS'), ('on', 'IN'), ('a', 'DT'), ('grueling', 'NN'), ('trek', 'NN'), ('across', 'IN'), ('the', 'DT'), ('burning', 'NN'), ('Arabian', 'JJ'), ('desert', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "taggedtextStanford_flat = [pair for sent in taggedtextStanford for pair in sent]\n",
    "print(taggedtextStanford_flat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
